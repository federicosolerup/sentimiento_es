# ğŸ§ ClasificaciÃ³n Multiclase - AnÃ¡lisis de Sentimiento en Voz Humana â€” Pipeline K-NN (Python + Librosa)

Este proyecto implementa un pipeline **end-to-end** para clasificar emociones en audios cortos (Negativo / Neutro / Positivo) utilizando extracciÃ³n de features acÃºsticas, ingenierÃ­a de features, normalizaciÃ³n y modelado con **K-Nearest Neighbors (KNN)**.
Incluye entrenamiento, predicciÃ³n sobre datos nuevos y evaluaciÃ³n final sobre el conjunto de test.

---

## ğŸ“ Estructura del proyecto

```
project/
â”‚â”€â”€ TRAIN/                         # Audios de entrenamiento
â”‚â”€â”€ TEST/                          # Audios de test
â”‚â”€â”€ 1_feature_extraction.py        # ExtracciÃ³n de features crudas
â”‚â”€â”€ 2_feature_engineering.py       # Agregaciones + transforms logarÃ­tmicas
â”‚â”€â”€ 3_modeling_knn.py              # Entrenamiento + validaciÃ³n + grÃ¡ficos
â”‚â”€â”€ 4_predict_test.py              # Pipeline completo de predicciÃ³n en TEST
â”‚â”€â”€ 5_evaluate_test.py             # MÃ©tricas y PCA 3D sobre TEST
â”‚â”€â”€ features_raw_train.csv
â”‚â”€â”€ features_engineered_train.csv
â”‚â”€â”€ knn_model.pkl
â”‚â”€â”€ scaler.pkl
â”‚â”€â”€ label_encoder.pkl
â”‚â”€â”€ predictions.csv
â”‚â”€â”€ README.md
```

---

## ğŸ“Œ 1. ExtracciÃ³n de Features (Script 1)

**Archivo:** `1_feature_extraction.py`
Fuente: 

Este script convierte cada `.wav` en un set de series temporales:

* RMS (energÃ­a)
* Zero Crossing Rate
* MFCCs (13 coeficientes)
* Centroid, Rolloff, Bandwidth
* Pitch (pYIN)
* EntropÃ­a de Shannon
* Exponente de Hurst

**Output generado:**

```
features_raw_train.csv
```

---

## ğŸ“Œ 2. IngenierÃ­a de Features (Script 2)

**Archivo:** `2_feature_engineering.py`
Fuente: 

Transforma las series temporales crudas en **features numÃ©ricas agregadas**:

* mean, std, var, max, min, median
* percentiles 25 y 75
* skewness y kurtosis
* RMS â†’ dB
* Pitch â†’ semitonos
* ZCR + spectral â†’ log(1+x)

**Output generado:**

```
features_engineered_train.csv
```

---

## ğŸ“Œ 3. Entrenamiento con KNN (Script 3)

**Archivo:** `3_modeling_knn.py`
Fuente: 

El pipeline de entrenamiento incluye:

* NormalizaciÃ³n con **StandardScaler**
* Train/validation estratificado 80/20
* BÃºsqueda del mejor **k**
* MÃ©tricas: accuracy, F1 macro/weighted
* GrÃ¡ficos:

  * Accuracy vs k
  * Matriz de confusiÃ³n
  * PCA 2D
  * Top features por correlaciÃ³n

**Outputs generados:**

```
knn_model.pkl
scaler.pkl
label_encoder.pkl
plot_accuracy_vs_k.png
plot_confusion_matrix.png
plot_pca_2d.png
plot_top_features.png
model_metrics.txt
```

---

## ğŸ“Œ 4. PredicciÃ³n en TEST (Script 4)

**Archivo:** `4_predict_test.py`
Fuente: 

Este script ejecuta automÃ¡ticamente:

1. ExtracciÃ³n de features de TEST
2. IngenierÃ­a de features
3. NormalizaciÃ³n usando el scaler del entrenamiento
4. PredicciÃ³n con el modelo KNN cargado
5. GeneraciÃ³n del archivo final de predicciones

**Outputs generados:**

```
features_raw_test.csv
features_engineered_test.csv
predictions.csv
```

---

## ğŸ“Œ 5. EvaluaciÃ³n Final en TEST (Script 5)

**Archivo:** `5_evaluate_test.py`
Fuente: 

Produce el anÃ¡lisis final del modelo:

* MÃ©tricas completas sobre TEST
* Matriz de confusiÃ³n en PNG
* PCA 3D coloreado por clase real
* ComparaciÃ³n entre etiquetas reales y predichas

**Outputs generados:**

```
plot_confusion_matrix_test.png
plot_pca_3d_test.png
test_metrics.txt
```

---

## â–¶ï¸ CÃ³mo ejecutar el proyecto

### 1. Preparar entorno

```bash
pip install numpy pandas librosa scikit-learn seaborn matplotlib tqdm joblib
```

### 2. Colocar audios en:

```
TRAIN/
TEST/
```

### 3. Ejecutar cada script en orden

```bash
python 1_feature_extraction.py
python 2_feature_engineering.py
python 3_modeling_knn.py
python 4_predict_test.py
python 5_evaluate_test.py
```

---

## ğŸ“Š Resultados esperados

* Modelo KNN entrenado con normalizaciÃ³n
* Visualizaciones completas
* Archivo `predictions.csv` listo para entregar
* Informe final de performance sobre TEST

---

## ğŸ“ Licencia

Este proyecto puede ser reutilizado y modificado libremente para fines acadÃ©micos.
